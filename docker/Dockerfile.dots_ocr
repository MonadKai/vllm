FROM docker.m.daocloud.io/vllm/vllm-openai:v0.10.0

LABEL maintainer="kai.liu <kai.liu@brgroup.com>"

ARG max_jobs=64
ENV MAX_JOBS=${max_jobs}

RUN pip install flash-attn==2.8.2 --no-build-isolation

# add transformers dots_ocr support
COPY dist/transformers-4.53.3.tar.gz /tmp/transformers-4.53.3.tar.gz
RUN pip uninstall transformers -y && pip install /tmp/transformers-4.53.3.tar.gz --no-deps && rm -rf /tmp/transformers-4.53.3.tar.gz

# add vllm kubernetes plugin support
COPY dist/vllm_kubernetes_plugin-0.1.0.tar.gz /tmp/vllm_kubernetes_plugin-0.1.0.tar.gz
RUN pip install /tmp/vllm_kubernetes_plugin-0.1.0.tar.gz --no-deps && rm -rf /tmp/vllm_kubernetes_plugin-0.1.0.tar.gz

# add vllm dots_ocr support
COPY vllm/model_executor/models/dots_ocr.py /usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/dots_ocr.py
COPY vllm/model_executor/models/registry.py /usr/local/lib/python3.12/dist-packages/vllm/model_executor/models/registry.py


ENTRYPOINT ["python3", "-m", "vllm.entrypoints.openai.api_server"]
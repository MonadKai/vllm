FROM m.daocloud.io/quay.io/ascend/vllm-ascend:v0.10.0rc1

# add vllm tei plugin support
COPY dist/vllm_tei_plugin-0.10.0.tar.gz /tmp/vllm_tei_plugin-0.10.0.tar.gz
RUN pip install /tmp/vllm_tei_plugin-0.10.0.tar.gz --no-deps && rm -rf /tmp/vllm_tei_plugin-0.10.0.tar.gz

# add vllm kubernetes plugin support
# COPY dist/vllm_kubernetes_plugin-0.1.0.tar.gz /tmp/vllm_kubernetes_plugin-0.1.0.tar.gz
# RUN pip install /tmp/vllm_kubernetes_plugin-0.1.0.tar.gz --no-deps && rm -rf /tmp/vllm_kubernetes_plugin-0.1.0.tar.gz

# add transformers parrot audio support
COPY dist/transformers-4.53.3.tar.gz /tmp/transformers-4.53.3.tar.gz
RUN pip uninstall transformers -y && pip install /tmp/transformers-4.53.3.tar.gz --no-deps && rm -rf /tmp/transformers-4.53.3.tar.gz

# torch==2.7.1 in vllm-ascend v0.10.0rc1s
RUN pip install torchaudio==2.7.1 -i https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple && pip install librosa==0.11.0 -i https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple


# add vllm mixed precision model loader
COPY vllm/model_executor/model_loader/mixed_precision_loader.py /vllm-workspace/vllm/vllm/model_executor/model_loader/mixed_precision_loader.py
COPY vllm/model_executor/model_loader/__init__.py /vllm-workspace/vllm/vllm/model_executor/model_loader/__init__.py
COPY vllm/config.py /vllm-workspace/vllm/vllm/config.py
COPY vllm/inputs/registry.py /vllm-workspace/vllm/vllm/inputs/registry.py

# add vllm parrot audio support
COPY dist/parrot_commons-0.1.0.tar.gz /tmp/parrot_commons-0.1.0.tar.gz
RUN pip install /tmp/parrot_commons-0.1.0.tar.gz --no-deps && rm -rf /tmp/parrot_commons-0.1.0.tar.gz

COPY vllm/model_executor/models/parrot_audio.py /vllm-workspace/vllm/vllm/model_executor/models/parrot_audio.py
COPY vllm/model_executor/models/parrot2_audio.py /vllm-workspace/vllm/vllm/model_executor/models/parrot2_audio.py
COPY vllm/model_executor/models/parrot2_audio_moe.py /vllm-workspace/vllm/vllm/model_executor/models/parrot2_audio_moe.py
COPY vllm/model_executor/models/registry.py /vllm-workspace/vllm/vllm/model_executor/models/registry.py

ENTRYPOINT ["vllm", "serve"]
